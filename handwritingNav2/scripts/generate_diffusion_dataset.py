#!/usr/bin/env python3
"""
ä¸ºæ‰©æ•£ç­–ç•¥ç”Ÿæˆä¸“å®¶æ¼”ç¤ºæ•°æ®é›†

ä½¿ç”¨ShortestPathFolloweræ”¶é›†ä¸“å®¶è½¨è¿¹ï¼Œä¿å­˜åˆ°ç£ç›˜ä¾›åç»­ç¦»çº¿è®­ç»ƒä½¿ç”¨ã€‚
æ•°æ®å°†ä¿å­˜åˆ° /mnt_data/skenav2/handwritingNav2/data/diffusion_dataset/
"""

import os
import sys

# å¿…é¡»åœ¨å¯¼å…¥å…¶ä»–åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå°è¯•ä½¿ç”¨GPUåŠ é€Ÿï¼‰
os.environ['MAGNUM_LOG'] = 'quiet'
os.environ['HABITAT_SIM_LOG'] = 'quiet'
os.environ['GLOG_minloglevel'] = '2'

# å°è¯•GPUæ¸²æŸ“é…ç½®ï¼ˆæé«˜é€Ÿåº¦ï¼‰
# å¦‚æœå¤±è´¥ä¼šè‡ªåŠ¨å›é€€åˆ°CPU
os.environ['MESA_GL_VERSION_OVERRIDE'] = '4.5'
os.environ['MESA_GLSL_VERSION_OVERRIDE'] = '450'

# è®¾ç½®EGLè®¾å¤‡ï¼ˆå°è¯•ä½¿ç”¨GPU 0ï¼‰
os.environ['EGL_DEVICE_ID'] = '0'
os.environ['MESA_LOADER_DRIVER_OVERRIDE'] = 'i965'

import cv2
import math
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Any, Union, cast
import datetime
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)
HABITAT_LAB_PATH = os.path.join(PROJECT_ROOT, 'habitat-lab')
sys.path.insert(0, HABITAT_LAB_PATH)

import habitat
from habitat.core.agent import Agent
from habitat.tasks.nav.shortest_path_follower import ShortestPathFollower
from habitat.sims.habitat_simulator.actions import HabitatSimActions
from habitat.utils.visualizations import maps
from habitat.sims.habitat_simulator.habitat_simulator import HabitatSim


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ExpertDemonstrationAgent(Agent):
    """ä½¿ç”¨ShortestPathFolloweræ”¶é›†ä¸“å®¶æ¼”ç¤ºçš„Agent"""
    
    def __init__(self, env: habitat.Env, goal_radius: float = 0.2, max_steps: int = 500):
        self.env = env
        self.shortest_path_follower = ShortestPathFollower(
            sim=cast(HabitatSim, env.sim),
            goal_radius=goal_radius,
            return_one_hot=False,
        )
        self.max_steps = max_steps
        self.step_count = 0
        
        # å­˜å‚¨è½¨è¿¹æ•°æ®
        self.observations_seq = []
        self.actions_seq = []
        self.positions_seq = []
        self.rotations_seq = []
        
    def reset(self) -> None:
        """é‡ç½®agentçŠ¶æ€"""
        self.step_count = 0
        self.observations_seq = []
        self.actions_seq = []
        self.positions_seq = []
        self.rotations_seq = []
        
    def act(self, observations: Dict) -> Union[int, None]:
        """æ‰§è¡Œä¸“å®¶åŠ¨ä½œ"""
        # æ£€æŸ¥æœ€å¤§æ­¥æ•°
        if self.step_count >= self.max_steps:
            logger.warning(f"è¾¾åˆ°æœ€å¤§æ­¥æ•° {self.max_steps}ï¼Œåœæ­¢å¯¼èˆª")
            return HabitatSimActions.STOP
        
        # è·å–ä¸“å®¶åŠ¨ä½œ
        next_action = self.shortest_path_follower.get_next_action(
            self.env.current_episode.goals[0].position
        )
        
        if next_action is None:
            # æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾ç›®æ ‡
            current_pos = self.env.sim.get_agent_state().position
            goal_pos = self.env.current_episode.goals[0].position
            distance = self.env.sim.geodesic_distance(current_pos, goal_pos)
            if isinstance(distance, np.ndarray):
                distance = distance.item()
            
            if distance <= self.shortest_path_follower.goal_radius:
                return HabitatSimActions.STOP
            else:
                logger.warning(f"æ²¡æœ‰åˆ°ç›®æ ‡ä½ç½®çš„æœ‰æ•ˆè·¯å¾„ï¼Œè·ç¦»: {distance:.2f}m")
                return HabitatSimActions.STOP
        
        return next_action
    
    def store_step(self, observations: Dict, action: int) -> None:
        """å­˜å‚¨å½“å‰æ­¥çš„æ•°æ®"""
        agent_state = self.env.sim.get_agent_state()
        
        self.observations_seq.append(observations)
        self.actions_seq.append(action)
        self.positions_seq.append(agent_state.position.copy())
        self.rotations_seq.append(agent_state.rotation)
        
        self.step_count += 1
        
    def get_trajectory_data(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´çš„è½¨è¿¹æ•°æ®"""
        return {
            'observations': self.observations_seq,
            'actions': self.actions_seq,
            'positions': self.positions_seq,
            'rotations': self.rotations_seq,
            'length': len(self.actions_seq)
        }


def save_episode_data(
    output_dir: str,
    episode_id: int,
    scene_id: str,
    trajectory_data: Dict[str, Any],
    split: str = 'train',
) -> bool:
    """ä¿å­˜å•ä¸ªepisodeçš„æ•°æ®"""
    try:
        scene_name = os.path.splitext(os.path.basename(scene_id))[0]
        scene_dir = os.path.join(output_dir, split, scene_name)
        traj_dir = os.path.join(scene_dir, f"episode_{episode_id}")
        os.makedirs(traj_dir, exist_ok=True)
        
        # éªŒè¯è½¨è¿¹è´¨é‡
        positions = np.array(trajectory_data['positions'])
        if len(positions) < 2:
            logger.warning(f"è½¨è¿¹å¤ªçŸ­ ({len(positions)} æ­¥)ï¼Œè·³è¿‡")
            return False
        
        # æ£€æŸ¥ä½ç½®æ˜¯å¦æœ‰å®é™…å˜åŒ–
        position_changes = np.diff(positions, axis=0)
        max_change = np.max(np.linalg.norm(position_changes, axis=1))
        total_distance = np.sum(np.linalg.norm(position_changes, axis=1))
        
        if max_change < 0.01:
            logger.warning(f"è½¨è¿¹å˜åŒ–å¤ªå° (max: {max_change:.4f}m)ï¼Œè·³è¿‡")
            return False
        
        if total_distance < 0.1:
            logger.warning(f"è½¨è¿¹æ€»è·ç¦»å¤ªçŸ­ ({total_distance:.4f}m)ï¼Œè·³è¿‡")
            return False
        
        logger.info(f"è½¨è¿¹ç»Ÿè®¡ - é•¿åº¦: {len(positions)}, æœ€å¤§å˜åŒ–: {max_change:.3f}m, æ€»è·ç¦»: {total_distance:.3f}m")
        
        # åªä¿å­˜æ·±åº¦å›¾ï¼ˆèŠ‚çœå­˜å‚¨ç©ºé—´ï¼Œæé«˜åŠ è½½é€Ÿåº¦ï¼‰
        observations = trajectory_data['observations']
        for t, obs in enumerate(observations):
            # ä¿å­˜Depth
            if 'depth' in obs:
                depth_path = os.path.join(traj_dir, f"depth_{t:05d}.npy")
                np.save(depth_path, obs['depth'])
                
                # ä¿å­˜æ·±åº¦å›¾å¯è§†åŒ–ï¼ˆä¾¿äºæ£€æŸ¥æ•°æ®è´¨é‡ï¼‰
                if t % 10 == 0:  # æ¯10å¸§ä¿å­˜ä¸€ä¸ªå¯è§†åŒ–
                    depth = obs['depth'].squeeze()
                    # å½’ä¸€åŒ–åˆ°0-255ç”¨äºå¯è§†åŒ–
                    depth_norm = np.clip(depth, 0.5, 5.0)
                    depth_vis = ((depth_norm - 0.5) / 4.5 * 255).astype(np.uint8)
                    # ä½¿ç”¨ä¼ªå½©è‰²æ˜ å°„
                    depth_color = cv2.applyColorMap(depth_vis, cv2.COLORMAP_VIRIDIS)
                    vis_path = os.path.join(traj_dir, f"depth_vis_{t:05d}.png")
                    cv2.imwrite(vis_path, depth_color)
            
            # ä¸ä¿å­˜RGBï¼ˆèŠ‚çœå­˜å‚¨ç©ºé—´ï¼‰
            # if 'rgb' in obs:
            #     rgb_path = os.path.join(traj_dir, f"rgb_{t:05d}.png")
            #     cv2.imwrite(rgb_path, cv2.cvtColor(obs['rgb'], cv2.COLOR_RGB2BGR))
        
        # ä¿å­˜åŠ¨ä½œåºåˆ—
        actions = np.array(trajectory_data['actions'], dtype=np.int32)
        actions_path = os.path.join(traj_dir, "actions.npy")
        np.save(actions_path, actions)
        
        # ä¿å­˜ä½ç½®åºåˆ—
        positions_path = os.path.join(traj_dir, "positions.npy")
        np.save(positions_path, positions)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'episode_id': episode_id,
            'scene_id': scene_id,
            'trajectory_length': len(actions),
            'total_distance': float(total_distance),
            'split': split,
        }
        metadata_path = os.path.join(traj_dir, "metadata.npy")
        np.save(metadata_path, metadata)
        
        logger.info(f"âœ… æˆåŠŸä¿å­˜è½¨è¿¹åˆ°: {traj_dir}")
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜episode {episode_id} æ•°æ®æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°ï¼šæ”¶é›†ä¸“å®¶æ¼”ç¤ºæ•°æ®"""
    
    # é…ç½®è¾“å‡ºç›®å½•
    output_dir = "/mnt_data/skenav2/handwritingNav2/data/diffusion_dataset"
    os.makedirs(output_dir, exist_ok=True)
    logger.info(f"æ•°æ®å°†ä¿å­˜åˆ°: {output_dir}")
    
    # ä½¿ç”¨ä¸“é—¨çš„PointNavé…ç½®ï¼ˆä¸åŠ è½½HandWritingNavï¼Œé€Ÿåº¦å¿«ï¼‰
    config_path = os.path.join(PROJECT_ROOT, "modeling/config/pointnav_datagen.yaml")
    
    if not os.path.exists(config_path):
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    logger.info(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    config = habitat.get_config(config_path)
    config.defrost()
    
    # ä½¿ç”¨CPUæ¸²æŸ“ï¼ˆDockerç¯å¢ƒä¸­GPU EGLä¸å¯ç”¨ï¼‰
    config.SIMULATOR.HABITAT_SIM_V0.GPU_DEVICE_ID = -1  # -1 = CPUæ¸²æŸ“
    logger.info("ä½¿ç”¨CPUæ¸²æŸ“æ¨¡å¼ï¼ˆç¨³å®šï¼Œé€‚åˆDockerç¯å¢ƒï¼‰")
    logger.info("æ³¨æ„ï¼šCPUæ¸²æŸ“è¾ƒæ…¢ï¼Œä½†ä¸ä¼šå‡ºé”™ã€‚å¦‚æœéœ€è¦GPUåŠ é€Ÿï¼Œéœ€è¦é…ç½®EGLè®¾å¤‡ã€‚")
    
    logger.info(f"ä½¿ç”¨æ•°æ®é›†: {config.DATASET.DATA_PATH}")
    
    # é…ç½®å·²ç»åŒ…å«æ‰€æœ‰å¿…è¦è®¾ç½®ï¼Œç›´æ¥å†»ç»“
    config.freeze()
    
    # åˆ›å»ºç¯å¢ƒ
    logger.info("åˆ›å»ºHabitatç¯å¢ƒ...")
    with habitat.Env(config=config) as env:
        # è·å–ç›®æ ‡åŠå¾„
        goal_radius = 0.2
        if len(env.episodes) > 0 and hasattr(env.episodes[0].goals[0], 'radius'):
            goal_radius = env.episodes[0].goals[0].radius or 0.2
        
        logger.info(f"ç›®æ ‡åŠå¾„: {goal_radius}m")
        logger.info(f"æ€»episodeæ•°: {len(env.episodes)}")
        
        # åˆ›å»ºä¸“å®¶agent
        agent = ExpertDemonstrationAgent(env, goal_radius=goal_radius)
        
        # ç»Ÿè®¡å˜é‡
        total_episodes = len(env.episodes)
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ•°æ®ç”Ÿæˆå‚æ•°
        max_episodes = None
        split_ratio = 0.9
        
        if hasattr(config, 'DATA_GENERATION'):
            # è¯»å–æœ€å¤§episodeæ•°é‡
            if hasattr(config.DATA_GENERATION, 'MAX_EPISODES'):
                max_eps = config.DATA_GENERATION.MAX_EPISODES
                if max_eps > 0:  # -1æˆ–0è¡¨ç¤ºå¤„ç†å…¨éƒ¨
                    max_episodes = max_eps
            
            # è¯»å–è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†æ¯”ä¾‹
            if hasattr(config.DATA_GENERATION, 'SPLIT_RATIO'):
                split_ratio = config.DATA_GENERATION.SPLIT_RATIO
        
        # åº”ç”¨episodeæ•°é‡é™åˆ¶
        if max_episodes is not None and max_episodes < total_episodes:
            logger.info(f"âš ï¸  é™åˆ¶å¤„ç†å‰ {max_episodes} ä¸ªepisodesï¼ˆæ€»å…±{len(env.episodes)}ä¸ªï¼‰")
            total_episodes = max_episodes
        else:
            logger.info(f"å°†å¤„ç†å…¨éƒ¨ {total_episodes} ä¸ªepisodes")
        
        saved_episodes = 0
        skipped_episodes = 0
        split_idx = int(split_ratio * total_episodes)
        
        logger.info(f"è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†æ¯”ä¾‹: {split_ratio:.1%} / {1-split_ratio:.1%}")
        
        # éå†episodes
        for episode_idx in range(total_episodes):
            try:
                logger.info(f"\n{'='*60}")
                logger.info(f"å¤„ç† Episode {episode_idx}/{total_episodes}")
                logger.info(f"{'='*60}")
                
                # é‡ç½®ç¯å¢ƒå’Œagent
                observations = env.reset()
                agent.reset()
                
                scene_id = env.current_episode.scene_id
                logger.info(f"åœºæ™¯: {os.path.basename(scene_id)}")
                logger.info(f"èµ·å§‹ä½ç½®: {env.sim.get_agent_state().position}")
                logger.info(f"ç›®æ ‡ä½ç½®: {env.current_episode.goals[0].position}")
                
                done = False
                step_count = 0
                
                # æ”¶é›†è½¨è¿¹
                while not done:
                    # è·å–ä¸“å®¶åŠ¨ä½œ
                    action = agent.act(observations)
                    
                    if action is None or action == HabitatSimActions.STOP:
                        logger.info(f"æ”¶åˆ°åœæ­¢åŠ¨ä½œï¼Œepisodeç»“æŸ")
                        break
                    
                    # å­˜å‚¨æ•°æ®
                    agent.store_step(observations, action)
                    
                    # æ‰§è¡ŒåŠ¨ä½œ
                    observations = env.step(action)
                    done = env.episode_over
                    step_count += 1
                    
                    if step_count % 50 == 0:
                        current_pos = env.sim.get_agent_state().position
                        logger.info(f"æ­¥éª¤ {step_count}: ä½ç½® {current_pos}")
                
                # è·å–æŒ‡æ ‡
                metrics = env.get_metrics()
                spl = metrics.get("spl", 0)
                success = metrics.get("success", 0)
                
                if isinstance(spl, np.ndarray):
                    spl = spl.item()
                if isinstance(success, np.ndarray):
                    success = success.item()
                
                logger.info(f"Episode {episode_idx} å®Œæˆ - SPL: {spl:.3f}, Success: {success}, æ­¥æ•°: {step_count}")
                
                # ç¡®å®šsplit
                split = "train" if episode_idx < split_idx else "test"
                
                # ä¿å­˜æ•°æ®
                trajectory_data = agent.get_trajectory_data()
                if save_episode_data(output_dir, episode_idx, scene_id, trajectory_data, split):
                    saved_episodes += 1
                else:
                    skipped_episodes += 1
                    
            except Exception as e:
                logger.error(f"å¤„ç†episode {episode_idx} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                skipped_episodes += 1
                continue
        
        # æ‰“å°æ€»ç»“
        logger.info(f"\n{'='*60}")
        logger.info(f"æ•°æ®æ”¶é›†å®Œæˆï¼")
        logger.info(f"{'='*60}")
        logger.info(f"å¤„ç†episodeæ•°: {total_episodes} / {len(env.episodes)}")
        logger.info(f"æˆåŠŸä¿å­˜: {saved_episodes}")
        logger.info(f"è·³è¿‡: {skipped_episodes}")
        logger.info(f"è®­ç»ƒé›†: ~{int(saved_episodes * split_ratio)} episodes")
        logger.info(f"æµ‹è¯•é›†: ~{saved_episodes - int(saved_episodes * split_ratio)} episodes")
        logger.info(f"æ•°æ®ä¿å­˜ä½ç½®: {output_dir}")
        
        if max_episodes is not None and max_episodes < len(env.episodes):
            logger.info(f"\nğŸ’¡ æç¤º: å½“å‰åªå¤„ç†äº†å‰ {max_episodes} ä¸ªepisodes")
            logger.info(f"   å¦‚éœ€å¤„ç†å…¨éƒ¨ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® DATA_GENERATION.MAX_EPISODES: -1")


if __name__ == "__main__":
    main()

